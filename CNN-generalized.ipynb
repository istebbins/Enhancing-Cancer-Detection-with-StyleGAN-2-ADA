{"cells":[{"cell_type":"markdown","metadata":{"id":"snY_iyC-NHmE"},"source":["https://www.kaggle.com/datasets/mohamedhanyyy/chest-ctscan-images/code?datasetId=839140&sortBy=voteCount"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"NeBUYDLGxGSS"},"outputs":[],"source":["\n","from tensorflow.keras.layers import Flatten, Dense, BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.models import Sequential"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":243,"status":"ok","timestamp":1701774304145,"user":{"displayName":"Benjamin","userId":"14931798628440562887"},"user_tz":-60},"id":"tJk9zuk41BAJ"},"outputs":[],"source":["# Define directories for training, validation, and test datasets\n","\n","\n","\n","train_dir =  'path to augmented or basic training directory'\n","test_dir = 'path to basic testing directory' #only want to test on non-synthetic data\n","val_dir = 'path to augmented or basic validation directory' #its okay if validation data is augmented \n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":297,"status":"ok","timestamp":1701774408887,"user":{"displayName":"Benjamin","userId":"14931798628440562887"},"user_tz":-60},"id":"_VQygoKX-bxj","outputId":"5c422a40-d941-454a-f4a5-bc5523269f5a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 621 images belonging to 2 classes.\n","Found 70 images belonging to 2 classes.\n","Found 144 images belonging to 2 classes.\n"]}],"source":["from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import resnet\n","\n","# Create separate ImageDataGenerator instances for each dataset. \n","#Use resnet preprocess function because we use resnet \n","\n","train_datagen = ImageDataGenerator(preprocessing_function=resnet.preprocess_input)\n","val_datagen = ImageDataGenerator(preprocessing_function=resnet.preprocess_input)\n","test_datagen = ImageDataGenerator(preprocessing_function=resnet.preprocess_input)\n","\n","# Create separate generators for training, validation, and test datasets\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(224, 224),\n","    batch_size=20,\n","    class_mode='binary',  # Use 'categorical' for multi-class classification\n","    shuffle=True,\n","    seed=42\n",")\n","\n","val_generator = val_datagen.flow_from_directory(\n","    val_dir,\n","    target_size=(224, 224),\n","    batch_size=20,\n","    class_mode='binary',\n","    shuffle=True  \n",")\n","\n","test_generator = test_datagen.flow_from_directory(\n","    test_dir,\n","    target_size=(224, 224),\n","    batch_size=20,\n","    class_mode='binary',\n","    shuffle=True  \n",")"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":219,"status":"ok","timestamp":1701774405281,"user":{"displayName":"Benjamin","userId":"14931798628440562887"},"user_tz":-60},"id":"crJHxgfjwNX3"},"outputs":[],"source":["img_size = (224, 224)\n","channels = 3\n","img_shape = (img_size[0], img_size[1], channels)\n","class_count = 2"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3147,"status":"ok","timestamp":1701774618868,"user":{"displayName":"Benjamin","userId":"14931798628440562887"},"user_tz":-60},"id":"1yDH9Isww09g","outputId":"70190122-abc1-47aa-e7f5-28d8d9afe4ab"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-12-11 14:57:07.983470: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," resnet50 (Functional)       (None, 2048)              23587712  \n","                                                                 \n"," flatten (Flatten)           (None, 2048)              0         \n","                                                                 \n"," batch_normalization (BatchN  (None, 2048)             8192      \n"," ormalization)                                                   \n","                                                                 \n"," dense (Dense)               (None, 50176)             102810624 \n","                                                                 \n"," dense_1 (Dense)             (None, 500)               25088500  \n","                                                                 \n"," dense_2 (Dense)             (None, 200)               100200    \n","                                                                 \n"," dense_3 (Dense)             (None, 50)                10050     \n","                                                                 \n"," dense_4 (Dense)             (None, 1)                 51        \n","                                                                 \n","=================================================================\n","Total params: 151,605,329\n","Trainable params: 128,013,521\n","Non-trainable params: 23,591,808\n","_________________________________________________________________\n"]}],"source":["from tensorflow.keras.applications import ResNet50\n","base_model = res_model = ResNet50(include_top=False, pooling='avg', weights='imagenet', input_shape = (img_shape)) #fine tuning! \n","\n","for layer in base_model.layers[:-2]: #Train the last 2 layers of resnet to improve accuracy. \n","    layer.trainable = False \n","    \n","model = Sequential([\n","    base_model,\n","    Flatten(),\n","    BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n","    Dense(224*224, kernel_regularizer= regularizers.l2(l= 0.016), activity_regularizer= regularizers.l1(0.006),\n","    bias_regularizer= regularizers.l1(0.006), activation= 'leaky_relu'),\n","    Dense(500, activation= 'leaky_relu'),\n","    Dense(200, activation= 'leaky_relu'), #leaky relu to avoid dying neurons \n","    Dense(50, activation= 'leaky_relu'),\n","    Dense(1, activation= 'sigmoid') #one neuron output for binary \n","])\n","\n","model.compile(Adam(learning_rate= 0.005), loss= 'binary_crossentropy', metrics= ['accuracy'])\n","\n","model.summary()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fynSeEuEySBC","outputId":"8b2bf10a-e974-4611-c04c-8357af4f1d03"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","32/32 [==============================] - ETA: 0s - loss: 475.6642 - accuracy: 0.8696"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: model/assets\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 188s 6s/step - loss: 475.6642 - accuracy: 0.8696 - val_loss: 656.5252 - val_accuracy: 0.7000 - lr: 0.0050\n","Epoch 2/5\n","32/32 [==============================] - ETA: 0s - loss: 472.0365 - accuracy: 0.9002"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: model/assets\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 188s 6s/step - loss: 472.0365 - accuracy: 0.9002 - val_loss: 266.0771 - val_accuracy: 0.8000 - lr: 0.0050\n","Epoch 3/5\n","32/32 [==============================] - ETA: 0s - loss: 209.8548 - accuracy: 0.9050"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: model/assets\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 257s 8s/step - loss: 209.8548 - accuracy: 0.9050 - val_loss: 138.4980 - val_accuracy: 0.9429 - lr: 0.0050\n","Epoch 4/5\n","32/32 [==============================] - ETA: 0s - loss: 153.3533 - accuracy: 0.9227"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: model/assets\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 230s 7s/step - loss: 153.3533 - accuracy: 0.9227 - val_loss: 91.0333 - val_accuracy: 0.9143 - lr: 0.0050\n","Epoch 5/5\n","32/32 [==============================] - ETA: 0s - loss: 79.1010 - accuracy: 0.9485"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: model/assets\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 283s 9s/step - loss: 79.1010 - accuracy: 0.9485 - val_loss: 48.8110 - val_accuracy: 0.9857 - lr: 0.0050\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: /Users/benmaizes/Dropbox/Mac/Desktop/DIS/DIS_NN/FinalProject/data/.ipynb_checkpoints/augmented_x/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: /Users/benmaizes/Dropbox/Mac/Desktop/DIS/DIS_NN/FinalProject/data/.ipynb_checkpoints/augmented_x/assets\n"]}],"source":["#adjust learnign rate, train extra layer \n","\n","batch_size = 20\n","epochs = 5\n","\n","patience = 3 \t\t# number of epochs to wait to adjust lr if monitored value does not improve\n","stop_patience = 3 \t# number of epochs to wait before stopping training if monitored value does not improve\n","\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","\n","checkpoint = ModelCheckpoint('model', monitor='val_loss', save_best_only=True)\n","early_stopping = EarlyStopping(monitor='val_loss', patience=stop_patience, restore_best_weights=True)\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.0005, patience=patience, min_lr=1e-6)\n","\n","history = model.fit(train_generator, validation_data=val_generator,\n","                    epochs= epochs, verbose= 1, shuffle= False,\n","                    callbacks=[checkpoint, early_stopping, reduce_lr],)\n","\n","percentage = \"x\" #modify this depending on the percentage of synthetic data\n","\n","model.save(f'/Users/benmaizes/Dropbox/Mac/Desktop/DIS/DIS_NN/FinalProject/data/.ipynb_checkpoints/{percentage}_x')\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1595,"status":"ok","timestamp":1701716265903,"user":{"displayName":"Benjamin","userId":"14931798628440562887"},"user_tz":-60},"id":"K-0c8c7U-XfC","outputId":"5ef6b546-0f66-463d-e6c7-b5c928a436ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["8/8 [==============================] - 24s 3s/step - loss: 49.3420 - accuracy: 0.9861\n","Test accuracy: 0.9861111044883728\n"]}],"source":["# Evaluate the model on the test set using the test generator\n","\n","test_loss, test_accuracy = model.evaluate(test_generator)\n","print(f\"Test accuracy: {test_accuracy}\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPqmWS8GsgAqyK027QORg7y","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":0}
